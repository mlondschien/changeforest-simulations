import logging
from time import perf_counter

import pandas as pd

from changeforest_simulations._simulate import simulate
from changeforest_simulations.methods import estimate_changepoints
from changeforest_simulations.score import adjusted_rand_score, hausdorff_distance
from changeforest_simulations.utils import string_to_kwargs

logger = logging.getLogger(__file__)

HEADER = "dataset,seed,method,score,left_hausdorff,right_hausdorff,symmetric_hausdorff,true_changepoints,estimated_changepoints,n_cpts,time\n"


def benchmark(method, dataset, seed, file_path=None, verify=False):
    """Run method on dataset generated by seed.

    If file_path is not None, check if file at the file_path exists. If not, raise.
    the file. Else, check whether method, dataset, seed combination has already been
    benchmarked. If so, and verify is False, return None. If verify is True, run method
    on dataset generated by seed and compare results. Raise if they are not identical.
    If the method, dataset, seed combination has not been benchmarked, run method on
    dataset generated by seed. If file_path is not None, write the results to the file.
    Returns the result.

    method: str
        String describing method to apply, for example, 'changeforest_bs'
    dataset: str
        String describing dataset. Kwargs can be added to the string, for example,
        'dirichlet__n_segments=5'.
    seed: int
        Seed passed to dataset generating process for reproducibility.
    file_path: str or pathlib.Path or None, optional, default=None
        Path to file where to store benchmark results.
    verify: bool, default=False
        If method, dataset, seed has already been benchmarked, compare existing results
        against new ones. Raise if they do not match.
    """
    if file_path is not None:
        with open(file_path, "r") as f:
            file_header = f.readline()

        if file_header != HEADER:
            raise ValueError(f"File {file_path} does not have the correct header.")

        existing_results = pd.read_csv(file_path)
        existing_results = existing_results[
            lambda x: x["dataset"].eq(dataset)
            & x["seed"].eq(seed)
            & x["method"].eq(method)
        ]
        if not existing_results.empty and not verify:
            logger.info(f"Skipping {seed} {dataset} {method}.")
            return
        if not existing_results.empty and verify:
            existing_results = existing_results.loc[0].to_dict()
            result = benchmark(method, dataset, seed, None, False)
            if (
                str(result["estimated_changepoints"])
                != existing_results["estimated_changepoints"]
            ):
                raise ValueError(
                    f"Inconsistent result for method={method}, dataset={dataset}, seed={seed}."
                )

    logger.info(f"Running {seed} {dataset} {method}.")

    change_points, time_series = simulate(dataset, seed=seed)
    _, dataset_kwargs = string_to_kwargs(dataset)
    _, method_kwargs = string_to_kwargs(method)

    if "minimal_relative_segment_length" in method_kwargs:
        minimal_relative_segment_length = method_kwargs[
            "minimal_relative_segment_length"
        ]
    elif "n_segments" in dataset_kwargs:
        minimal_relative_segment_length = 1 / dataset_kwargs["n_segments"] / 10
    else:
        minimal_relative_segment_length = 0.01

    tic = perf_counter()
    estimate = estimate_changepoints(
        time_series,
        method,
        minimal_relative_segment_length=minimal_relative_segment_length,
    )
    toc = perf_counter()

    score = adjusted_rand_score(change_points, estimate)
    left_hausdorff = hausdorff_distance(change_points, estimate)
    right_hausdorff = hausdorff_distance(estimate, change_points)
    symmetric_hausdorff = max(left_hausdorff, right_hausdorff)

    result = {
        "dataset": dataset,
        "seed": seed,
        "method": method,
        "score": score,
        "left_hausdorff": left_hausdorff,
        "right_hausdorff": right_hausdorff,
        "symmetric_hausdorff": symmetric_hausdorff,
        "true_changepoints": list(change_points),
        "estimated_changepoints": list(estimate),
        "n_cpts": len(estimate) - 2,
        "time": toc - tic,
    }

    if file_path is not None:
        if not file_path.exists():
            raise ValueError(f"File {file_path} does not exist.")

        existing_results = pd.read_csv(file_path)[["dataset", "seed", "method"]]
        if not existing_results[
            lambda x: x["dataset"].eq(dataset)
            & x["seed"].eq(seed)
            & x["method"].eq(method)
        ].empty:
            raise ValueError(f"Duplicate result {dataset} {seed} {method}.")

        with open(file_path, "a") as f:
            f.write(
                f"""{dataset},{seed},{method},{score},{left_hausdorff},{right_hausdorff},{symmetric_hausdorff},"{str(list(change_points))}","{str(list(estimate))}",{len(estimate) - 2},{toc-tic}\n"""
            )

    return result
